---
---

@string{aps = {American Physical Society,}}


@article{yu2023Retro,
  abbr={arXiv},
  title={ Retromorphic Testing: A New Approach to the Test Oracle Problem },
  author={Yu, Boxi and Mang, Qiuyang and Guo, Qingshuo and He, Pinjia},
  journal={ArXiv},
  year={2023},
  selected={true},
  code={https://github.com/CUHK-Shenzhen-SE/RetromorphicTesting},
  arxiv={2310.06433},
  pdf={https://arxiv.org/pdf/2310.06433.pdf}
}

@article{yu2024LightAD,
  abbr={ICSE},
  title={Deep Learning or Classical Machine Learning? An Empirical Study on Log-Based Anomaly Detection},
  author={Yu, Boxi and Yao, Jiayi and Fu, Qiuai and Zhong, Zhiqing and Xie, Haotian and Wu, Yaoliang and Ma, Yuchi and He, Pinjia},
  journal={ICSE'24: International Conference on Software Engineering},
  year={2024},
  selected={true},
  code={https://github.com/BoxiYu/LightAD},
  pdf={LightAD.pdf}
}

@article{yu2024dspyg,
  abbr={CASW},
  title={DSPy Guardrails: Building Safe LLM Applications via Self-Refining Language Model Pipelines},
  author={Yu, Boxi and He, Pinjia},
  journal={Compound AI Systems Workshop},
  year={2024},
  selected={true},
  code={https://github.com/BoxiYu/DSPy-Guardrails},
  pdf={DSPy_Guardrails.pdf}
}


@article{mang2024EQR,
  abbr={ICSE},
  title={Testing Graph Database Systems via Equivalent Query Rewriting},
  author={Mang, Qiuyang and Fang, Aoyang and Yu, Boxi and Chen, Hanfei and He, Pinjia},
  journal={ICSE'24: International Conference on Software Engineering},
  year={2024},
  selected={true}
}

@article{zhong2025deprecation,
  abbr={ICSE},
  title={An Empirical Study on Package-Level Deprecation in Python Ecosystem},
  author={Zhong, Zhiqing and He, Shilin and Wang, Haoxuan and Yu, Boxi and Yang, Haowen and He, Pinjia},
  journal={arXiv preprint arXiv:2408.10327},
  year={2025},
  selected={true}
}

@article{yu2023tin,
  author = {Yu, Boxi and Hu, Yiyan and Mang, Qiuyang and Hu, Wenhan and He, Pinjia},
  title = {Automated Testing and Improvement of Named Entity Recognition Systems},
  year = {2023},
  isbn = {9798400703270},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3611643.3616295},
  doi = {10.1145/3611643.3616295},
  abstract = {Named entity recognition (NER) systems have seen rapid progress in recent years due to the development of deep neural networks. These systems are widely used in various natural language processing applications, such as information extraction, question answering, and sentiment analysis. However, the complexity and intractability of deep neural networks can make NER systems unreliable in certain circumstances, resulting in incorrect predictions. For example, NER systems may misidentify female names as chemicals or fail to recognize the names of minority groups, leading to user dissatisfaction. To tackle this problem, we introduce TIN, a novel, widely applicable approach for automatically testing and repairing various NER systems. The key idea for automated testing is that the NER predictions of the same named entities under similar contexts should be identical. The core idea for automated repairing is that similar named entities should have the same NER prediction under the same context. We use TIN to test two SOTA NER models and two commercial NER APIs, i.e., Azure NER and AWS NER. We manually verify 784 of the suspicious issues reported by TIN and find that 702 are erroneous issues, leading to high precision (85.0\%-93.4\%) across four categories of NER errors: omission, over-labeling, incorrect category, and range error. For automated repairing, TIN achieves a high error reduction rate (26.8\%-50.6\%) over the four systems under test, which successfully repairs 1,056 out of the 1,877 reported NER errors.},
  booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages = {883–894},
  numpages = {12},
  keywords = {software repairing, named entity recognition, Metamorphic testing, AI software},
  location = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
  series = {ESEC/FSE 2023},
  abbr={ESEC/FSE},
  title={Automated Testing and Improvement of Named Entity Recognition Systems},
  author={Yu, Boxi and Hu, Yiyan and Mang, Qiuyang and Hu, Wenhan and He, Pinjia},
  journal={ESEC/FSE'23: Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pdf={https://arxiv.org/pdf/2308.07937.pdf},
  code={https://github.com/RobustNLP/TestIC},
  year={2023},
  selected={true},
  slides={TIN_slides.pdf}
}




@inproceedings{yu2023rome,
  author = {Yu, Boxi and Zhong, Zhiqing and Li, Jiaqi and Yang, Yixing and He, Shilin and He, Pinjia},
  title = {ROME: Testing Image Captioning Systems via Recursive Object Melting},
  abbr={ISSTA},
  year = {2023},
  isbn = {9798400702211},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3597926.3598094},
  doi = {10.1145/3597926.3598094},
  booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
  pages = {766–778},
  numpages = {13},
  keywords = {Metamorphic testing, image captioning, AI software, testing},
  location = {Seattle, WA, USA},
  series = {ISSTA 2023},
  selected={true},
  code={https://github.com/RobustNLP/TestNER},
  html={https://dl.acm.org/doi/abs/10.1145/3597926.3598094},
  pdf={https://arxiv.org/pdf/2306.02228.pdf},
  slides={Rome_slides.pdf}
}






@inproceedings{yu2022automated,
author = {Yu, Boxi and Zhong, Zhiqing and Qin, Xinran and Yao, Jiayi and Wang, Yuancheng and He, Pinjia},
title = {Automated Testing of Image Captioning Systems},
year = {2022},
isbn = {9781450393799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533767.3534389},
doi = {10.1145/3533767.3534389},
abstract = {Image captioning (IC) systems, which automatically generate a text description of the salient objects in an image (real or synthetic), have seen great progress over the past few years due to the development of deep neural networks. IC plays an indispensable role in human society, for example, labeling massive photos for scientific studies and assisting visually-impaired people in perceiving the world. However, even the top-notch IC systems, such as Microsoft Azure Cognitive Services and IBM Image Caption Generator, may return incorrect results, leading to the omission of important objects, deep misunderstanding, and threats to personal safety. To address this problem, we propose MetaIC, the first metamorphic testing approach to validate IC systems. Our core idea is that the object names should exhibit directional changes after object insertion. Specifically, MetaIC (1) extracts objects from existing images to construct an object corpus; (2) inserts an object into an image via novel object resizing and location tuning algorithms; and (3) reports image pairs whose captions do not exhibit differences in an expected way. In our evaluation, we use MetaIC to test one widely-adopted image captioning API and five state-of-the-art (SOTA) image captioning models. Using 1,000 seeds, MetaIC successfully reports 16,825 erroneous issues with high precision (84.9\%-98.4\%). There are three kinds of errors: misclassification, omission, and incorrect quantity. We visualize the errors reported by MetaIC, which shows that flexible overlapping setting facilitates IC testing by increasing and diversifying the reported errors. In addition, MetaIC can be further generalized to detect label errors in the training dataset, which has successfully detected 151 incorrect labels in MS COCO Caption, a standard dataset in image captioning.},
booktitle = {Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {467–479},
numpages = {13},
keywords = {image captioning, testing, Metamorphic testing, AI software},
location = {<conf-loc>, <city>Virtual</city>, <country>South Korea</country>, </conf-loc>},
series = {ISSTA 2022},
title={Automated testing of image captioning systems},
abbr={ISSTA},
author={Yu, Boxi and Zhong, Zhiqing and Qin, Xinran and Yao, Jiayi and Wang, Yuancheng and He, Pinjia},
booktitle={Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages={467--479},
year={2022},
selected={true},
code={https://github.com/RobustNLP/TestIC},
html={https://dl.acm.org/doi/abs/10.1145/3533767.3534389},
pdf={https://arxiv.org/pdf/2206.06550.pdf},
slides={MetaIC_slides.pdf}
}
